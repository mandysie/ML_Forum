{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf32ff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "收斂後樣本數量：5926\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 載入資料\n",
    "ptt_df = pd.read_csv(\"ptt_語料_處理後.csv\")\n",
    "mobile01_df = pd.read_csv(\"mobile01_處理後.csv\")\n",
    "finfo_df = pd.read_csv(\"finfo_posts_產險_壽險_投資型.csv\")\n",
    "scam_keywords_df = pd.read_csv(\"cleaned/500精簡詐騙字詞_UTF8.csv\", header=None)\n",
    "\n",
    "# 合併所有來源\n",
    "combined_df = pd.concat([ptt_df, mobile01_df, finfo_df], ignore_index=True)\n",
    "\n",
    "# 正規化欄位名稱\n",
    "combined_df.columns = [col.strip().lower() for col in combined_df.columns]\n",
    "scam_keywords = scam_keywords_df[0].dropna().unique().tolist()\n",
    "\n",
    "# 取出所有帳號資料（發文、留言、Mobile01）\n",
    "post_authors = combined_df['發文者帳號'].dropna().astype(str)\n",
    "comment_authors = combined_df['留言帳號'].dropna().astype(str)\n",
    "mobile01_authors = combined_df['author'].dropna().astype(str)\n",
    "\n",
    "# 統計帳號出現次數\n",
    "all_accounts = pd.concat([post_authors, comment_authors, mobile01_authors], ignore_index=True)\n",
    "account_counts = all_accounts.value_counts()\n",
    "single_appearance_accounts = set(account_counts[account_counts == 1].index)\n",
    "\n",
    "# 整合所有文字內容\n",
    "combined_df['完整內容'] = combined_df[['內容', '發文內容', '留言內容', 'content']].fillna('').agg(' '.join, axis=1)\n",
    "\n",
    "# 篩選帳號只出現一次的樣本\n",
    "account_related_records = combined_df[\n",
    "    combined_df['發文者帳號'].isin(single_appearance_accounts) |\n",
    "    combined_df['留言帳號'].isin(single_appearance_accounts) |\n",
    "    combined_df['author'].isin(single_appearance_accounts)\n",
    "].copy()\n",
    "\n",
    "# 篩掉包含詐騙關鍵字的樣本\n",
    "account_related_records['包含詐騙詞'] = account_related_records['完整內容'].apply(\n",
    "    lambda x: any(keyword in x for keyword in scam_keywords)\n",
    ")\n",
    "filtered_records = account_related_records[~account_related_records['包含詐騙詞']]\n",
    "\n",
    "# 最終樣本數\n",
    "print(f\"收斂後樣本數量：{len(filtered_records)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5c36ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'收斂樣本_無詐騙詞_帳號只出現一次.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the filtered (收斂後) records to a CSV file\n",
    "output_path = \"收斂樣本_無詐騙詞_帳號只出現一次.csv\"\n",
    "filtered_records.to_csv(output_path, index=False)\n",
    "\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5034d6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'詐騙特徵建構與異常偵測.ipynb'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 準備完整 .ipynb 所需的程式碼內容\n",
    "notebook_code = {\n",
    "    \"cells\": [\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# 詐騙帳號偵測特徵建構與異常分析\\n\",\n",
    "                \"本 notebook 將處理收斂過的樣本資料，建構詐騙特徵，並使用 Isolation Forest 與 One-Class SVM 進行異常行為偵測。\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"import pandas as pd\\n\",\n",
    "                \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\",\n",
    "                \"from sklearn.ensemble import IsolationForest\\n\",\n",
    "                \"from sklearn.svm import OneClassSVM\\n\",\n",
    "                \"from IPython.display import display\\n\",\n",
    "                \"\\n\",\n",
    "                \"# 讀取資料\\n\",\n",
    "                \"df = pd.read_csv(\\\"收斂樣本_無詐騙詞_帳號只出現一次.csv\\\")\\n\",\n",
    "                \"scam_keywords = pd.read_csv(\\\"cleaned/500精簡詐騙字詞_UTF8.csv\\\", header=None)[0].dropna().unique().tolist()\\n\",\n",
    "                \"df.columns = [col.strip().lower() for col in df.columns]\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# 整合欄位與時間處理\\n\",\n",
    "                \"df['帳號'] = df[['發文者帳號', '留言帳號', 'author']].bfill(axis=1).iloc[:, 0]\\n\",\n",
    "                \"df['內容'] = df[['內容', '發文內容', '留言內容', 'content']].fillna('').agg(' '.join, axis=1)\\n\",\n",
    "                \"df['是否主文'] = df['是否主文'].fillna(False).astype(int)\\n\",\n",
    "                \"df['時間'] = df[['發文時間', '留言時間', 'post_time', 'time']].bfill(axis=1).iloc[:, 0]\\n\",\n",
    "                \"df['時間'] = pd.to_datetime(df['時間'], errors='coerce')\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# 特徵工程\\n\",\n",
    "                \"account_counts = df['帳號'].value_counts()\\n\",\n",
    "                \"df['帳號出現次數'] = df['帳號'].map(account_counts)\\n\",\n",
    "                \"df['是否凌晨'] = df['時間'].dt.hour.apply(lambda x: 1 if pd.notnull(x) and 0 <= x < 6 else 0)\\n\",\n",
    "                \"df['是否含詐騙字詞'] = df['內容'].apply(lambda x: any(word in x for word in scam_keywords)).astype(int)\\n\",\n",
    "                \"df['內容長度'] = df['內容'].apply(len)\\n\",\n",
    "                \"來源_dummies = pd.get_dummies(df['來源'], prefix='來源')\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# TF-IDF 特徵\\n\",\n",
    "                \"tfidf_vectorizer = TfidfVectorizer(max_features=100)\\n\",\n",
    "                \"tfidf_matrix = tfidf_vectorizer.fit_transform(df['內容'].fillna(''))\\n\",\n",
    "                \"tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=[f'tfidf_{i}' for i in range(tfidf_matrix.shape[1])])\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# 合併所有特徵\\n\",\n",
    "                \"feature_set = pd.concat([\\n\",\n",
    "                \"    df[['帳號', '帳號出現次數', '是否凌晨', '是否含詐騙字詞', '內容長度', '是否主文']].reset_index(drop=True),\\n\",\n",
    "                \"    來源_dummies.reset_index(drop=True),\\n\",\n",
    "                \"    tfidf_df.reset_index(drop=True)\\n\",\n",
    "                \"], axis=1)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# 異常偵測模型\\n\",\n",
    "                \"iso_model = IsolationForest(random_state=42)\\n\",\n",
    "                \"feature_set['isolation_anomaly_score'] = iso_model.fit_predict(feature_set.drop(columns=['帳號']))\\n\",\n",
    "                \"\\n\",\n",
    "                \"svm_model = OneClassSVM(gamma='scale', nu=0.1)\\n\",\n",
    "                \"feature_set['svm_anomaly_score'] = svm_model.fit_predict(feature_set.drop(columns=['帳號']))\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# 顯示前幾筆結果\\n\",\n",
    "                \"display(feature_set.head())\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# 匯出為 CSV\\n\",\n",
    "                \"feature_set.to_csv(\\\"完整詐騙偵測特徵表.csv\\\", index=False)\"\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"kernelspec\": {\n",
    "            \"display_name\": \"Python 3\",\n",
    "            \"language\": \"python\",\n",
    "            \"name\": \"python3\"\n",
    "        },\n",
    "        \"language_info\": {\n",
    "            \"name\": \"python\",\n",
    "            \"version\": \"3.8\"\n",
    "        }\n",
    "    },\n",
    "    \"nbformat\": 4,\n",
    "    \"nbformat_minor\": 5\n",
    "}\n",
    "\n",
    "# 儲存為 .ipynb 檔案\n",
    "import json\n",
    "\n",
    "notebook_path = \"詐騙特徵建構與異常偵測.ipynb\"\n",
    "with open(notebook_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(notebook_code, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "notebook_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94a6fa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 假設你已經訓練好這個 vectorizer\u001b[39;00m\n\u001b[0;32m      2\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m內容\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 查看每個 tfidf 特徵名稱（對應詞語）\u001b[39;00m\n\u001b[0;32m      6\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# 假設你已經訓練好這個 vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['內容'].fillna(''))\n",
    "\n",
    "# 查看每個 tfidf 特徵名稱（對應詞語）\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# 建立對應字典\n",
    "tfidf_feature_mapping = {f'tfidf_{i}': word for i, word in enumerate(feature_names)}\n",
    "\n",
    "# 顯示前幾個看看\n",
    "for i in range(10):\n",
    "    print(f'tfidf_{i} => {tfidf_feature_mapping[f\"tfidf_{i}\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a80bb53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TFIDF_詞彙命名特徵表.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 重新讀取原始內容資料（非特徵表，避免重複 tfidf）\n",
    "df = pd.read_csv(\"收斂樣本_無詐騙詞_帳號只出現一次.csv\")\n",
    "df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "# 整合內容欄位\n",
    "df['內容'] = df[['內容', '發文內容', '留言內容', 'content']].fillna('').agg(' '.join, axis=1)\n",
    "\n",
    "# 重建 TfidfVectorizer，這次保留原始詞彙作為欄位名\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['內容'].fillna(''))\n",
    "\n",
    "# 使用詞彙名稱建立欄位名\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_df_named = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# 輸出新的 TF-IDF 特徵表（含詞彙名）\n",
    "output_path = \"TFIDF_詞彙命名特徵表.csv\"\n",
    "tfidf_df_named.to_csv(output_path, index=False)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5979f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TFIDF_詞彙命名特徵表.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 重新載入原始收斂樣本資料\n",
    "df = pd.read_csv(\"收斂樣本_無詐騙詞_帳號只出現一次.csv\")\n",
    "df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "# 整合內容欄位\n",
    "df['內容'] = df[['內容', '發文內容', '留言內容', 'content']].fillna('').agg(' '.join, axis=1)\n",
    "\n",
    "# 建立乾淨版本的 TfidfVectorizer\n",
    "clean_vectorizer = TfidfVectorizer(\n",
    "    max_features=100,\n",
    "    stop_words=['com', 'http', 'https', 'imgur', 'wrote', '恕刪', '分享', '笑死'],\n",
    "    token_pattern=r\"(?u)\\b\\w{2,}\\b\"  # 只保留長度 >= 2 的詞，排除純數字與符號\n",
    ")\n",
    "\n",
    "# 擬合與轉換\n",
    "clean_tfidf_matrix = clean_vectorizer.fit_transform(df['內容'].fillna(''))\n",
    "clean_feature_names = clean_vectorizer.get_feature_names_out()\n",
    "\n",
    "# 建立 DataFrame 並輸出\n",
    "clean_tfidf_df = pd.DataFrame(clean_tfidf_matrix.toarray(), columns=clean_feature_names)\n",
    "clean_tfidf_output_path = \".csv\"\n",
    "clean_tfidf_df.to_csv(clean_tfidf_output_path, index=False)\n",
    "\n",
    "clean_tfidf_output_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
