{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f192bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定義語氣分類詞典\n",
    "tone_map = {\n",
    "    \"立即\": \"催促\",\n",
    "    \"馬上\": \"催促\",\n",
    "    \"請在\": \"催促\",\n",
    "    \"限時\": \"催促\",\n",
    "    \"否則\": \"威脅\",\n",
    "    \"通緝\": \"恐嚇\",\n",
    "    \"警察\": \"權威假冒\",\n",
    "    \"法院\": \"權威假冒\",\n",
    "    \"客服\": \"假冒正規\",\n",
    "    \"司法\": \"恐嚇\",\n",
    "    \"監管\": \"恐嚇\",\n",
    "    \"保證金\": \"誘導\",\n",
    "    \"中獎\": \"誘導\",\n",
    "    \"轉帳\": \"指示\",\n",
    "    \"ATM\": \"指示\",\n",
    "    \"帳戶\": \"指示\",\n",
    "    \"醫藥費\": \"求助\",\n",
    "    \"救我\": \"求助\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e2c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     詞語  出現次數    語氣分類\n",
      "324  支付    60  其他/未分類\n",
      "896  保單    53  其他/未分類\n",
      "214  提供    45  其他/未分類\n",
      "148  立即    40      催促\n",
      "144  帳戶    39      指示\n",
      "2    需要    38  其他/未分類\n",
      "866  保險    37  其他/未分類\n",
      "419  公司    24  其他/未分類\n",
      "962  保費    23  其他/未分類\n",
      "222  通知    23  其他/未分類\n",
      "193  XX    22  其他/未分類\n",
      "911  投保    21  其他/未分類\n",
      "468  領取    21  其他/未分類\n",
      "225  辦理    21  其他/未分類\n",
      "143  銀行    19  其他/未分類\n",
      "94   才能    19  其他/未分類\n",
      "168  資料    18  其他/未分類\n",
      "294  客服    17    假冒正規\n",
      "346  避免    16  其他/未分類\n",
      "13   一筆    16  其他/未分類\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "with open(\"關鍵字.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# 自定義停用詞（可擴充）\n",
    "stopwords = set([\n",
    "    '我們', '您', '你的', '我的', '是', '在', '了', '就', '都', '以', '為', '請', '的', \n",
    "    '這裡', '您好', '您好！', '您好，', '若', '若您', '請您', '現在', '將', '可能'\n",
    "])\n",
    "\n",
    "tokens = jieba.lcut(text)\n",
    "tokens = [word for word in tokens if word.strip() not in stopwords and len(word.strip()) > 1]\n",
    "\n",
    "# 詞頻\n",
    "token_counts = Counter(tokens)\n",
    "\n",
    "# 加語氣分類\n",
    "tone_map = {\n",
    "    \"立即\": \"催促\", \"馬上\": \"催促\", \"請在\": \"催促\", \"限時\": \"催促\",\n",
    "    \"否則\": \"威脅\", \"通緝\": \"恐嚇\", \"警察\": \"權威假冒\", \"法院\": \"權威假冒\",\n",
    "    \"客服\": \"假冒正規\", \"司法\": \"恐嚇\", \"監管\": \"恐嚇\", \"保證金\": \"誘導\",\n",
    "    \"中獎\": \"誘導\", \"轉帳\": \"指示\", \"ATM\": \"指示\", \"帳戶\": \"指示\",\n",
    "    \"醫藥費\": \"求助\", \"救我\": \"求助\",\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(token_counts.items(), columns=[\"詞語\", \"出現次數\"])\n",
    "df[\"語氣分類\"] = df[\"詞語\"].map(tone_map).fillna(\"其他/未分類\")\n",
    "df = df.sort_values(by=\"出現次數\", ascending=False)\n",
    "\n",
    "df.to_csv(\"去除贅詞_詐騙語氣統計.csv\", index=False)\n",
    "print(df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41faff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "     ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 2.6/19.2 MB 16.7 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 8.1/19.2 MB 22.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 13.9/19.2 MB 24.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  19.1/19.2 MB 25.7 MB/s eta 0:00:01\n",
      "     --------------------------------------- 19.2/19.2 MB 23.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314527 sha256=c25bcdeb1987ceaa798da2b47f937849eeeff189a84837324cc6bbd4848b4324\n",
      "  Stored in directory: c:\\users\\robby1206\\appdata\\local\\pip\\cache\\wheels\\c9\\69\\31\\d56d90b22a1777b0b231e234b00302a55be255930f8bd92dcd\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0a12f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "支付\n",
      "保單\n",
      "提供\n",
      "立即 (緊急)\n",
      "帳戶 (指示)\n",
      "保險\n",
      "保費\n",
      "通知\n",
      "XX\n",
      "投保\n",
      "領取\n",
      "辦理\n",
      "銀行\n",
      "才能\n",
      "客服 (假冒)\n",
      "避免\n",
      "一筆\n",
      "確認\n",
      "否則 (威脅)\n",
      "安全\n",
      "涉及\n",
      "以免\n",
      "保障\n",
      "費用\n",
      "客戶\n",
      "繳納\n",
      "申請\n",
      "發現\n",
      "活動\n",
      "000\n",
      "調查\n",
      "身分\n",
      "資金\n",
      "聯絡\n",
      "保證\n",
      "手續費\n",
      "帳號\n",
      "資訊以\n",
      "扣款\n",
      "萬元\n",
      "中心\n",
      "交易\n",
      "訂單\n",
      "退款\n",
      "資訊\n",
      "盜用\n",
      "重新\n",
      "不然\n",
      "指示\n",
      "理賠\n",
      "配合\n",
      "異常\n",
      "保證金 (誘餌)\n",
      "未繳\n",
      "無法\n",
      "付款\n",
      "收益\n",
      "包裹\n",
      "信用卡\n",
      "50\n",
      "處理\n",
      "更新\n",
      "所有\n",
      "登入\n",
      "獲得\n",
      "資格\n",
      "這是\n",
      "取消\n",
      "醫療\n",
      "繳清\n",
      "電話\n",
      "專案\n",
      "提醒\n",
      "操作\n",
      "現金\n",
      "問題\n",
      "罰款\n",
      "協助\n",
      "獎品\n",
      "投資\n",
      "受益人\n",
      "10\n",
      "即可\n",
      "驗證\n",
      "一次\n",
      "升級\n",
      "凍結\n",
      "身份\n",
      "犯罪\n",
      "中獎 (誘餌)\n",
      "如需\n",
      "商品\n",
      "連結\n",
      "感謝\n",
      "VIP\n",
      "繳費\n",
      "平台\n",
      "手續\n",
      "只要\n",
      "監管 (恐嚇)\n",
      "利息\n",
      "證明\n",
      "退費\n",
      "需繳\n",
      "要求\n",
      "保險理\n",
      "程序\n",
      "參加\n",
      "不及\n",
      "目前\n",
      "失效\n",
      "30\n",
      "不想\n",
      "以便\n",
      "即將\n",
      "網站\n",
      "每年\n",
      "收取\n",
      "顯示\n",
      "政府\n",
      "本金\n",
      "錯過\n",
      "手機\n",
      "案件\n",
      "今日\n",
      "今天\n",
      "電腦\n",
      "支持\n",
      "號碼\n",
      "盡快\n",
      "撥款\n",
      "抽獎\n",
      "回饋\n",
      "500\n",
      "有人\n",
      "懷疑\n",
      "5%\n",
      "海外\n",
      "親屬\n",
      "一定\n",
      "貸款\n",
      "額度\n",
      "按照\n",
      "生效\n",
      "出現\n",
      "幸運\n",
      "差額\n",
      "偵測\n",
      "匯款\n",
      "已經\n",
      "近期\n",
      "意外\n",
      "尚未\n",
      "請先\n",
      "1000\n",
      "購買\n",
      "投入\n",
      "機會\n",
      "提醒您\n",
      "金額\n",
      "欠款\n",
      "100\n",
      "指定\n",
      "翻倍\n",
      "必須\n",
      "獎金\n",
      "退回\n",
      "補繳\n",
      "密碼\n",
      "損失\n",
      "購物\n",
      "最新\n",
      "一份\n",
      "我現\n",
      "恭喜\n",
      "準備\n",
      "幫忙\n",
      "遇到\n",
      "領回\n",
      "賠償\n",
      "過期\n",
      "醫院\n",
      "不是\n",
      "地址\n",
      "助您\n",
      "繳保費\n",
      "學校\n",
      "正在\n",
      "非法\n",
      "即刻\n",
      "簽署\n",
      "詐騙\n",
      "實性\n",
      "機構\n",
      "之前\n",
      "建議\n",
      "加保\n",
      "增加\n",
      "沒有\n",
      "可疑\n",
      "卡號\n",
      "利用\n",
      "旅遊\n",
      "名額\n",
      "核准\n",
      "證金\n",
      "放款\n",
      "一位\n",
      "影響\n",
      "額外\n",
      "訴訟\n",
      "存款\n",
      "警告\n",
      "寄送\n",
      "重要\n",
      "明天\n",
      "墊付\n",
      "請將\n",
      "放棄\n",
      "一年\n",
      "加入\n",
      "回報\n",
      "證件\n",
      "涉嫌\n",
      "需先\n",
      "親愛的\n",
      "小時\n",
      "10%\n",
      "流程\n",
      "檢察官\n",
      "一起\n",
      "領獎\n",
      "依法\n",
      "先繳\n",
      "相關\n",
      "2000\n",
      "不要\n",
      "填寫\n",
      "成功\n",
      "平安\n",
      "強制\n",
      "本案\n",
      "孩子\n",
      "請點擊\n",
      "鎖定\n",
      "停機\n",
      "自動\n",
      "相信\n",
      "運費\n",
      "法律\n",
      "軟體\n",
      "人壽\n",
      "每月\n",
      "網路\n",
      "以確\n",
      "解鎖\n",
      "專員\n",
      "審查\n",
      "優惠\n",
      "提交\n",
      "如果\n",
      "逾期\n",
      "費以\n",
      "不法\n",
      "可選擇\n",
      "退還\n",
      "服務\n",
      "一張\n",
      "退保\n",
      "終止\n",
      "監控\n",
      "立刻\n",
      "暫時\n",
      "使用\n",
      "方案\n",
      "錯誤\n",
      "分紅\n",
      "ATM (指示)\n",
      "最近\n",
      "我們將\n",
      "文件\n",
      "效力\n",
      "權益\n",
      "價值\n",
      "推薦\n",
      "不會\n",
      "停用\n",
      "高額\n",
      "不足\n",
      "本行\n",
      "專線\n",
      "交保\n",
      "用以\n",
      "年度\n",
      "和解\n",
      "先借\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def process_fraud_keywords(csv_file):\n",
    "    \"\"\"\n",
    "    Processes a CSV file containing fraud keywords, adds tone markers,\n",
    "    and filters the list based on frequency and relevance.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tone-marked fraud keywords.\n",
    "    \"\"\"\n",
    "\n",
    "    fraud_keywords = []\n",
    "    tone_mapping = {\n",
    "        \"催促\": \"(緊急)\",\n",
    "        \"威脅\": \"(威脅)\",\n",
    "        \"誘導\": \"(誘餌)\",\n",
    "        \"假冒正規\": \"(假冒)\",\n",
    "        \"指示\": \"(指示)\",\n",
    "        \"恐嚇\": \"(恐嚇)\",\n",
    "        \"權威假冒\": \"(假冒權威)\"\n",
    "    }\n",
    "\n",
    "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header row\n",
    "        for row in reader:\n",
    "            try:\n",
    "                word, frequency, category = row\n",
    "                frequency = int(frequency)\n",
    "                tone = tone_mapping.get(category, \"\")  # Get tone from mapping\n",
    "                if tone:\n",
    "                    word = f\"{word} {tone}\"  # Add tone marker\n",
    "                # Filter based on frequency (adjust thresholds as needed)\n",
    "                if frequency >= 3:  # Keep words with frequency >= 3\n",
    "                    fraud_keywords.append((word, frequency))\n",
    "            except ValueError as e:\n",
    "                print(f\"Skipping row due to error: {row} - {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    # Sort by frequency (descending)\n",
    "    fraud_keywords.sort(key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # Further filtering and reduction (customize as needed)\n",
    "    filtered_keywords = []\n",
    "    for word, frequency in fraud_keywords:\n",
    "        #Remove generic terms (customize the list)\n",
    "        generic_terms = [\"資料\", \"公司\", \"需要\", \"可以\", \"真的\", \"系統\", \"完成\"]\n",
    "        if word.split(\" \")[0] not in generic_terms: #check the base word, not including tone\n",
    "            filtered_keywords.append(word)\n",
    "\n",
    "    return filtered_keywords[:500] # Limit to 500 words\n",
    "\n",
    "# Example usage:\n",
    "csv_file = \"去除贅詞_詐騙語氣統計.csv\"\n",
    "processed_keywords = process_fraud_keywords(csv_file)\n",
    "\n",
    "for keyword in processed_keywords:\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9a9f124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed keywords saved to processed_fraud_keywords.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def process_fraud_keywords(csv_file, output_file):\n",
    "    \"\"\"\n",
    "    Processes a CSV file containing fraud keywords, adds tone markers,\n",
    "    filters the list based on frequency and relevance, and saves the\n",
    "    results to a new CSV file.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the input CSV file.\n",
    "        output_file (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    fraud_keywords = []\n",
    "    tone_mapping = {\n",
    "        \"催促\": \"(緊急)\",\n",
    "        \"威脅\": \"(威脅)\",\n",
    "        \"誘導\": \"(誘餌)\",\n",
    "        \"假冒正規\": \"(假冒)\",\n",
    "        \"指示\": \"(指示)\",\n",
    "        \"恐嚇\": \"(恐嚇)\",\n",
    "        \"權威假冒\": \"(假冒權威)\"\n",
    "    }\n",
    "\n",
    "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header row\n",
    "        for row in reader:\n",
    "            try:\n",
    "                word, frequency, category = row\n",
    "                frequency = int(frequency)\n",
    "                tone = tone_mapping.get(category, \"\")  # Get tone from mapping\n",
    "                if tone:\n",
    "                    word = f\"{word} {tone}\"  # Add tone marker\n",
    "\n",
    "                if frequency >= 3:  # Keep words with frequency >= 3\n",
    "                    fraud_keywords.append((word, frequency))\n",
    "            except ValueError as e:\n",
    "                print(f\"Skipping row due to error: {row} - {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    # Sort by frequency (descending)\n",
    "    fraud_keywords.sort(key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # Further filtering and reduction (customize as needed)\n",
    "    filtered_keywords = []\n",
    "    for word, frequency in fraud_keywords:\n",
    "        #Remove generic terms (customize the list)\n",
    "        generic_terms = [\"資料\", \"公司\", \"需要\", \"可以\", \"真的\", \"系統\", \"完成\"]\n",
    "        if word.split(\" \")[0] not in generic_terms: #check the base word, not including tone\n",
    "            filtered_keywords.append(word)\n",
    "\n",
    "    filtered_keywords = filtered_keywords[:500] # Limit to 500 words\n",
    "\n",
    "    # Save to CSV\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"keyword\"])  # Header row\n",
    "        for keyword in filtered_keywords:\n",
    "            writer.writerow([keyword])\n",
    "\n",
    "# Example usage:\n",
    "csv_file = \"去除贅詞_詐騙語氣統計.csv\"\n",
    "output_file = \"processed_fraud_keywords.csv\"\n",
    "process_fraud_keywords(csv_file, output_file)\n",
    "\n",
    "print(f\"Processed keywords saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8de45384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed keywords saved to processed_fraud_keywords.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def process_fraud_keywords(csv_file, output_file):\n",
    "    \"\"\"\n",
    "    Processes a CSV file containing fraud keywords, adds tone markers,\n",
    "    filters the list based on frequency and relevance, and saves the\n",
    "    results to a new CSV file.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the input CSV file.\n",
    "        output_file (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    fraud_keywords = []\n",
    "    tone_mapping = {\n",
    "        \"催促\": \"(緊急)\",\n",
    "        \"威脅\": \"(威脅)\",\n",
    "        \"誘導\": \"(誘餌)\",\n",
    "        \"假冒正規\": \"(假冒)\",\n",
    "        \"指示\": \"(指示)\",\n",
    "        \"恐嚇\": \"(恐嚇)\",\n",
    "        \"權威假冒\": \"(假冒權威)\"\n",
    "    }\n",
    "\n",
    "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header row\n",
    "        for row in reader:\n",
    "            try:\n",
    "                word, frequency, category = row\n",
    "                frequency = int(frequency)\n",
    "                tone = tone_mapping.get(category, \"\")  # Get tone from mapping\n",
    "                if tone:\n",
    "                    word = f\"{word} {tone}\"  # Add tone marker\n",
    "\n",
    "                if frequency >= 2:  # Keep words with frequency >= 2 (Reduced Threshold)\n",
    "                    fraud_keywords.append((word, frequency))\n",
    "            except ValueError as e:\n",
    "                print(f\"Skipping row due to error: {row} - {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    # Sort by frequency (descending)\n",
    "    fraud_keywords.sort(key=lambda item: item[1], reverse=True)\n",
    "\n",
    "    # Further filtering and reduction (customize as needed)\n",
    "    filtered_keywords = []\n",
    "    for word, frequency in fraud_keywords:\n",
    "        #Remove generic terms (customize the list)\n",
    "        generic_terms = [\"資料\", \"公司\", \"需要\", \"可以\", \"真的\", \"系統\"] # Reduced Generic Terms\n",
    "        if word.split(\" \")[0] not in generic_terms: #check the base word, not including tone\n",
    "            filtered_keywords.append(word)\n",
    "\n",
    "    filtered_keywords = filtered_keywords[:500] # Limit to 500 words\n",
    "\n",
    "    # Save to CSV\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"keyword\"])  # Header row\n",
    "        for keyword in filtered_keywords:\n",
    "            writer.writerow([keyword])\n",
    "\n",
    "# Example usage:\n",
    "csv_file = \"去除贅詞_詐騙語氣統計.csv\"\n",
    "output_file = \"processed_fraud_keywords.csv\"\n",
    "process_fraud_keywords(csv_file, output_file)\n",
    "\n",
    "print(f\"Processed keywords saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3674bfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'500精簡詐騙字詞_UTF8.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重新載入檔案（因為執行狀態重置）\n",
    "import pandas as pd\n",
    "\n",
    "# 嘗試以多種編碼打開 CSV 檔案\n",
    "encodings_to_try = [\"utf-8\", \"utf-8-sig\", \"big5\", \"cp950\", \"gbk\"]\n",
    "file_path = \"500精簡詐騙字詞.csv\"\n",
    "\n",
    "for enc in encodings_to_try:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding=enc)\n",
    "        detected_encoding = enc\n",
    "        break\n",
    "    except UnicodeDecodeError:\n",
    "        continue\n",
    "\n",
    "# 重新儲存為 UTF-8 格式\n",
    "output_path = \"500精簡詐騙字詞_UTF8.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "output_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
